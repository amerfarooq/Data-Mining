{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from sklearn import datasets\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class InternalNode:\n",
    "  \n",
    "#   def __init__(self):\n",
    "#     self.right = None\n",
    "#     self.left = None\n",
    "#     self.level = 0\n",
    "   \n",
    "#   def set_right_child(self, right):\n",
    "#     if (right is None):\n",
    "#       raise RuntimeError(\"Cannot set right-child of node as None\")\n",
    "#     else:\n",
    "#       self.right = right\n",
    "    \n",
    "#   def set_left_child(self, left):\n",
    "#     if (left is None):\n",
    "#       raise RuntimeError(\"Cannot set left-child of node as None\")\n",
    "#     else:\n",
    "#       self.left = left\n",
    "  \n",
    "#   def set_test(self, feat, feat_val, feat_name):\n",
    "#     self.feat = feat\n",
    "#     self.feat_val = feat_val\n",
    "#     self.feat_name = feat_name\n",
    "  \n",
    "#   def get_test(self):    \n",
    "#       return self.feat_name + ' < ' + str(self.feat_val)\n",
    "  \n",
    "#   def set_level(self, lvl):\n",
    "#     self.level = lvl\n",
    "  \n",
    "#   def __str__(self):\n",
    "#     return self.get_test()\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "# class LeafNode:\n",
    "  \n",
    "#   def __init__(self, main_class):\n",
    "#     self.main_class = main_class\n",
    "#     self.level = 0\n",
    "    \n",
    "#   def get_class(self):\n",
    "#     return self.main_class\n",
    "  \n",
    "#   def __str__(self):\n",
    "#     return str(self.main_class)\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "# class DecisionTree: \n",
    "  \n",
    "#   def __init__(self, data, labels = None):\n",
    "#     self.train(data, labels)\n",
    "    \n",
    "#   def train(self, data, labels = None):\n",
    "    \n",
    "#     if (labels is not None):\n",
    "#       targets = np.array(labels.reshape(-1, 1))\n",
    "#       data = np.append(data, targets, axis=1)\n",
    "    \n",
    "#     self.num_features = data.shape[1] - 1\n",
    "#     self.root = self._build_tree(data)\n",
    "    \n",
    "  \n",
    "#   def _build_tree(self, data):\n",
    "#     main_class = self._get_dominant_class(data)\n",
    "    \n",
    "#     if main_class is not None:\n",
    "#       print (\"returned main class \", main_class)\n",
    "#       return LeafNode(main_class)\n",
    "  \n",
    "#     else:\n",
    "#       max_info_gain = 0\n",
    "#       best_partition = []\n",
    "      \n",
    "#       for feature in range(0, self.num_features):\n",
    "#         possible_partitions = self._get_possible_partitions(data, feature)\n",
    "#         print (\"\\npossible partitons \", possible_partitions, \"\\n\")\n",
    "        \n",
    "#         for feat_val in possible_partitions:\n",
    "#           print (\"\\ntesting val: \", feat_val, \" feat: \", feature)\n",
    "#           part_a, part_b = self._partition_data(data, feature, feat_val)\n",
    "#           print (\"part a: \", part_a.shape, \" part b: \", part_b.shape)\n",
    "          \n",
    "#           info_gain = self._evaluate_partitions(data, part_a, part_b)\n",
    "#           print(\"old_max: \", max_info_gain)\n",
    "          \n",
    "#           if (info_gain > max_info_gain):\n",
    "#             print(\"new_max: \", info_gain)\n",
    "#             max_info_gain = info_gain\n",
    "#             best_partition = [feature, feat_val]\n",
    "            \n",
    "#       print (best_partition)\n",
    "#       left, right = self._partition_data(data, best_partition[0], best_partition[1])\n",
    "      \n",
    "#       node = InternalNode()\n",
    "     \n",
    "#       node.set_test( best_partition[0], best_partition[1], columns[best_partition[0]] )\n",
    "#       print( \"left \", left.shape )\n",
    "#       node.set_left_child( self._build_tree(left) )\n",
    "#       print( \"right \", right.shape )\n",
    "#       node.set_right_child( self._build_tree(right) )\n",
    "      \n",
    "#       return node\n",
    "    \n",
    " \n",
    "#   def print_tree(self):\n",
    "#     root = Node(str(self.root))\n",
    "#     self._ppt(root, self.root)\n",
    "#     print_tree(root)\n",
    "# #     self._preorder_traversal(self.root)\n",
    "    \n",
    "  \n",
    "#   def predict_point(self, datapoint):\n",
    "#     if datapoint.shape[0] != self.num_features + 1:\n",
    "#       raise RuntimeError(\"Datapoint contains incorrect number of features!\")\n",
    "    \n",
    "#     return self._predict(datapoint)\n",
    "    \n",
    "    \n",
    "#   def predict_set(self, data):\n",
    "#     if data.shape[1] - 1 != self.num_features:\n",
    "#       raise RuntimeError(\"Data contains incorrect number of features!\")\n",
    "      \n",
    "#     predictions = []  \n",
    "    \n",
    "#     for point in data:\n",
    "#       predictions.append(self._predict(point[:-1]))\n",
    "      \n",
    "#     return predictions\n",
    "  \n",
    "  \n",
    "#   def _predict(self, point):\n",
    "#     curr_node = self.root\n",
    "    \n",
    "#     while (True):\n",
    "#       if isinstance(curr_node, LeafNode):\n",
    "#         return str(curr_node)\n",
    "\n",
    "#       else:\n",
    "#         if (point[curr_node.feat] < curr_node.feat_val):\n",
    "#           curr_node = curr_node.left\n",
    "        \n",
    "#         else:\n",
    "#           curr_node = curr_node.right\n",
    "  \n",
    "    \n",
    "    \n",
    "#   def _ppt(self, pptnode, treenode):\n",
    "    \n",
    "#     if isinstance(treenode.right, InternalNode):\n",
    "#       right = Node(str(treenode.right), pptnode)\n",
    "#       self._ppt(right, treenode.right)\n",
    "    \n",
    "#     elif isinstance(treenode.right, LeafNode):\n",
    "#       Node(str(treenode.right), pptnode)\n",
    "#       return\n",
    "    \n",
    "#     if isinstance(treenode.left, InternalNode):\n",
    "#       left = Node(str(treenode.left), pptnode)\n",
    "#       self._ppt(left, treenode.left)\n",
    "    \n",
    "#     elif isinstance(treenode.left, LeafNode):\n",
    "#       Node(str(treenode.left), pptnode)\n",
    "#       return\n",
    "      \n",
    "   \n",
    "    \n",
    "#   def _preorder_traversal(self, node):\n",
    "#     if isinstance(node, LeafNode):\n",
    "#       print (node.get_class())\n",
    "    \n",
    "#     else:\n",
    "#       print (node.get_test())\n",
    "#       self._preorder_traversal(node.left)\n",
    "#       self._preorder_traversal(node.right)\n",
    "\n",
    "\n",
    "#   def _get_possible_partitions(self, data, feature):\n",
    "#     \"\"\"\n",
    "#     Parameters:\n",
    "#       data (dataframe): Contains all datapoints with their feature values\n",
    "#       feature (int):    A column index of the given data that corresponds to the feature on\n",
    "#                         which to partiton the data\n",
    "                        \n",
    "#     Returns:\n",
    "#       list: Possible values of the given feature on which the given data can be partitioned\n",
    "    \n",
    "#     \"\"\"\n",
    "#     feat_vals = np.sort(data[:, feature])\n",
    "#     return (feat_vals[1:] + feat_vals[:-1]) / 2\n",
    "      \n",
    "    \n",
    "#   def _partition_data(self, data, feature, feature_val):\n",
    "#     less_than = data[data[:, feature] < feature_val]\n",
    "#     greater_than = data[data[:, feature] >= feature_val]\n",
    "    \n",
    "#     return less_than, greater_than\n",
    "    \n",
    "    \n",
    "#   def _evaluate_partitions(self, data, part_a, part_b, metric = 'ent'):\n",
    "#     if metric == 'ent':\n",
    "#       return self._get_info_gain(data, part_a, part_b)\n",
    "    \n",
    "\n",
    "#   def _get_info_gain(self, data, part_a, part_b):\n",
    "#     \"\"\"\n",
    "#     Returns the information gain if data partitioned into part_a and part_b\n",
    "    \n",
    "#     info gain = ent_parent - [(p_a * ent_a) + (p_b * ent_b)]\n",
    "    \n",
    "#     p_a: probability of class a datapoints in data\n",
    "#     p_b: probability of class b datapoints in data\n",
    "#     ent_a: entropy of partition a\n",
    "#     ent_b: entropy of partition b\n",
    "    \n",
    "#     \"\"\"\n",
    "#     total_size = data.shape[0]\n",
    "#     part_a_size = part_a.shape[0]\n",
    "#     part_b_size = part_b.shape[0]\n",
    "#     print (\"t_size: \", total_size, \" pa_size: \", part_a_size, \" pb_size: \", part_b_size)\n",
    "    \n",
    "#     parent_ent = self._get_entropy(data, f=False)\n",
    "#     part_a_ent = self._get_entropy(part_a)\n",
    "#     part_b_ent = self._get_entropy(part_b)\n",
    "    \n",
    "#     f = parent_ent - (((part_a_size / total_size) * part_a_ent) + ((part_b_size / total_size) * part_b_ent))\n",
    "#     print (\"parent_ent: \", parent_ent, \" part_a_ent: \", part_a_ent, \" part_b_ent: \", part_b_ent, \" final: \", f)\n",
    "#     return f\n",
    "\n",
    "#   def _get_entropy(self, partition, f=True):\n",
    "#     value, counts = np.unique(partition[:,-1], return_counts=True)\n",
    "    \n",
    "#     if f: \n",
    "#       print(\"val: \", value, \" counts: \", counts)\n",
    "    \n",
    "#     return entropy(counts, base=2)\n",
    "  \n",
    "  \n",
    "#   def _get_dominant_class(self, data):\n",
    "#     \"\"\"\n",
    "#     Check if the class label of the given datapoints is the same. If it is, return that class. Otherwise,\n",
    "#     return None.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     # Check if the last column (which corresponds to the class) has only one unique value\n",
    "#     print(\"checking dom class: \")\n",
    "#     if np.unique(data[:, -1]).size == 1:\n",
    "#       print(np.unique(data[:, -1]), \" ret: \", data[0, -1])\n",
    "#       return data[0,-1]\n",
    "    \n",
    "#     else:\n",
    "#       return None  \n",
    "    \n",
    "    \n",
    "# #------------------------------------------------TEST CODE------------------------------------------------------\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "  \n",
    "  def __init__(self, info_gain, purity = 0, class_label = None):\n",
    "    self.purity = purity\n",
    "    self.info_gain = info_gain\n",
    "    self.class_label = class_label\n",
    "    self.right = None\n",
    "    self.left = None\n",
    "    self.level = 0\n",
    "    \n",
    "  def set_test(self, feat, feat_val, feat_name):\n",
    "    self.feat = feat\n",
    "    self.feat_val = feat_val\n",
    "    self.feat_name = feat_name\n",
    "    \n",
    "  def get_test(self):    \n",
    "      return self.feat_name + ' < ' + str(self.feat_val)\n",
    "  \n",
    "  def is_leaf(self):\n",
    "    if self.right == None and self.left == None:\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "      \n",
    "  def __str__(self):\n",
    "    return self.get_test()\n",
    "  \n",
    "\n",
    "    \n",
    "class DecisionTree: \n",
    "  \n",
    "  def __init__(self, data, purity = 0.95, max_depth = 10, feature_names = None):\n",
    "    self.purity = purity\n",
    "    self.num_features = data.shape[1] - 1\n",
    "    self.max_depth = max_depth\n",
    "\n",
    "    if (feature_names is None):\n",
    "      self.feature_names = np.arange(0, self.num_features)\n",
    "    else:\n",
    "      self.feature_names = feature_names\n",
    "    \n",
    "    self.root = self._build_tree(data) \n",
    "    \n",
    "\n",
    "  def _build_tree(self, data):\n",
    "    main_class = self._get_dominant_class(data)\n",
    "    \n",
    "    if main_class is not None:\n",
    "      return Node(class_label = main_class, info_gain=0)\n",
    "  \n",
    "    else:\n",
    "      max_info_gain = 0\n",
    "      best_partition = []\n",
    "      \n",
    "      for feature in range(0, self.num_features):\n",
    "        possible_partitions = self._get_possible_partitions(data, feature)\n",
    "        \n",
    "        for feat_val in possible_partitions:\n",
    "          part_a, part_b = self._partition_data(data, feature, feat_val)\n",
    "          \n",
    "          info_gain = self._evaluate_partitions(data, part_a, part_b)\n",
    "          \n",
    "          if (info_gain > max_info_gain):\n",
    "            max_info_gain = info_gain\n",
    "            best_partition = [feature, feat_val]\n",
    "            \n",
    "      left, right = self._partition_data(data, best_partition[0], best_partition[1])\n",
    "      \n",
    "      node = Node(info_gain = max_info_gain)\n",
    "      \n",
    "      node.set_test( best_partition[0], best_partition[1], self.feature_names[best_partition[0]] )\n",
    "      node.left = self._build_tree(left)\n",
    "      node.right = self._build_tree(right)\n",
    "      \n",
    "      return node\n",
    "    \n",
    " \n",
    "  def print_tree(self):\n",
    "    self._preorder_traversal(self.root)\n",
    "    \n",
    "  \n",
    "  def _preorder_traversal(self, node):\n",
    "    if node.is_leaf():\n",
    "      print (node.class_label)\n",
    "    \n",
    "    else:\n",
    "      print (node.get_test())\n",
    "      self._preorder_traversal(node.left)\n",
    "      self._preorder_traversal(node.right)\n",
    "  \n",
    "  \n",
    "  def predict_point(self, datapoint):\n",
    "    if datapoint.shape[0] != self.num_features + 1:\n",
    "      raise RuntimeError(\"Datapoint contains incorrect number of features!\")\n",
    "    \n",
    "    return self._predict(datapoint)\n",
    "    \n",
    "    \n",
    "  def predict_set(self, data):\n",
    "    if data.shape[1] - 1 != self.num_features:\n",
    "      raise RuntimeError(\"Data contains incorrect number of features!\")\n",
    "      \n",
    "    predictions = []  \n",
    "    \n",
    "    for point in data:\n",
    "      predictions.append(self._predict(point[:-1]))\n",
    "      \n",
    "    return predictions\n",
    "  \n",
    "  \n",
    "  def _predict(self, point):\n",
    "    curr_node = self.root\n",
    "    \n",
    "    while (True):\n",
    "      if curr_node.is_leaf():\n",
    "        return curr_node.class_label\n",
    "\n",
    "      else:\n",
    "        if (point[curr_node.feat] < curr_node.feat_val):\n",
    "          curr_node = curr_node.left\n",
    "        \n",
    "        else:\n",
    "          curr_node = curr_node.right\n",
    "  \n",
    "\n",
    "  def _get_possible_partitions(self, data, feature):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "      data (dataframe): Contains all datapoints with their feature values\n",
    "      feature (int):    A column index of the given data that corresponds to the feature on\n",
    "                        which to partiton the data\n",
    "                        \n",
    "    Returns:\n",
    "    --------\n",
    "      list: Possible values of the given feature on which the given data can be partitioned\n",
    "    \n",
    "    \"\"\"\n",
    "    feat_vals = np.sort(data[:, feature])\n",
    "    return (feat_vals[1:] + feat_vals[:-1]) / 2\n",
    "      \n",
    "    \n",
    "  def _partition_data(self, data, feature, feature_val):\n",
    "    less_than = data[data[:, feature] < feature_val]\n",
    "    greater_than = data[data[:, feature] >= feature_val]\n",
    "    \n",
    "    return less_than, greater_than\n",
    "    \n",
    "    \n",
    "  def _evaluate_partitions(self, data, part_a, part_b, metric = 'ent'):\n",
    "    if metric == 'ent':\n",
    "      return self._get_info_gain(data, part_a, part_b)\n",
    "    \n",
    "\n",
    "  def _get_info_gain(self, data, part_a, part_b):\n",
    "    \"\"\"\n",
    "    Returns the information gain if data partitioned into part_a and part_b\n",
    "    \n",
    "    info gain = ent_parent - [(p_a * ent_a) + (p_b * ent_b)]\n",
    "    \n",
    "    p_a: probability of class a datapoints in data\n",
    "    p_b: probability of class b datapoints in data\n",
    "    ent_a: entropy of partition a\n",
    "    ent_b: entropy of partition b\n",
    "    \n",
    "    \"\"\"\n",
    "    total_size = data.shape[0]\n",
    "    part_a_size = part_a.shape[0]\n",
    "    part_b_size = part_b.shape[0]\n",
    "    \n",
    "    parent_ent = self._get_entropy(data)\n",
    "    part_a_ent = self._get_entropy(part_a)\n",
    "    part_b_ent = self._get_entropy(part_b)\n",
    "    \n",
    "    return parent_ent - (((part_a_size / total_size) * part_a_ent) + ((part_b_size / total_size) * part_b_ent))\n",
    "\n",
    "  \n",
    "  def _get_entropy(self, partition):\n",
    "    value, counts = np.unique(partition[:,-1], return_counts=True)\n",
    "    return entropy(counts, base=2)\n",
    "  \n",
    "  \n",
    "  def _get_dominant_class(self, data):\n",
    "    \"\"\"\n",
    "    If purity of the most frequent class in data is above a certain threshold, return that class, else return None. \n",
    "    \n",
    "    \"\"\"\n",
    "    classes, counts = np.unique(data[:, -1], return_counts=True)\n",
    "    \n",
    "    if (np.amax(counts) / np.sum(counts)) >= self.purity:\n",
    "      return data[0, -1]\n",
    "    \n",
    "    else:\n",
    "      return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-bba9a68ba465>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mfinal_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpurity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mtest_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('./iris.data').values\n",
    "# np.random.shuffle(data)\n",
    "# columns = ['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "\n",
    "data_set = datasets.load_iris()\n",
    "data = np.array(data_set[\"data\"])\n",
    "targets = np.array(data_set[\"target\"]).reshape(-1, 1)\n",
    "final_dataset = np.append(data, targets, axis=1)\n",
    "# np.random.shuffle(final_dataset)\n",
    "\n",
    "\n",
    "# split = 120\n",
    "\n",
    "# train = final_dataset[:split]\n",
    "# test = final_dataset[split:]\n",
    "test =  final_dataset\n",
    "\n",
    "dt = DecisionTree(train, purity=1)\n",
    "\n",
    "test_total = test.shape[0]\n",
    "correct = 0\n",
    "\n",
    "for point in test:\n",
    "#   print (\"actual: \" + str(point[-1]), \"      predicted: \" +  str(dt.predict_point(point)))\n",
    "  \n",
    "  if (math.isclose(point[-1], dt.predict_point(point))):\n",
    "    correct += 1\n",
    "  else:\n",
    "    print (\"actual: \" + str(point[-1]), \"      predicted: \" +  str(dt.predict_point(point)))\n",
    "    \n",
    "print (\"\\ncorrect: \" + str(correct), \" |wrong: \" + str(test_total - correct), \" |total: \" + str(test_total), \" |accuracy: \" + str(correct / float(test_total)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
