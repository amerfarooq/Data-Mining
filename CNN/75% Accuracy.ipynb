{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "WjoLW3XJnhew"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Convolution2D\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.mode.chained_assignment = None\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/mydrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "xcQWIfv-nhe9"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/content/mydrive/My Drive/DM_DATA/Train.csv', usecols=['label']).astype(int)\n",
    "train_data = pd.read_csv('/content/mydrive/My Drive/DM_DATA/interpolated_train.csv')\n",
    "test_data = pd.read_csv('/content/mydrive/My Drive/DM_DATA/interpolated_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNht16Fvnhff"
   },
   "outputs": [],
   "source": [
    "def imgShow(im):\n",
    "    res = np.array(im).reshape(32,32)\n",
    "    plt.imshow(res,interpolation='nearest', cmap = plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "YiolG-zanhfn",
    "outputId": "f8043092-86f0-4d92-df87-809bad522858"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX4hMkfiFyJT/A17QjN2/8enVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgShow(train_data.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSEhYTc5nhgb"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, labels)\n",
    "\n",
    "X_train = X_train.values.reshape(X_train.shape[0], 32, 32, 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], 32, 32, 1)\n",
    "test = test_data.values.reshape(test_data.shape[0], 32, 32, 1)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "nzEJGN54nhgh",
    "outputId": "4733e9ed-242e-4b2a-e825-2c3337e09126"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgShow(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aRulsHe6Hqg"
   },
   "outputs": [],
   "source": [
    "# Model 2 with 67% accuracy on 100 epochs\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(48, 3, 3, border_mode='same', input_shape=(32, 32, 1)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(48, 3, 3))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Conv2D(96, 3, 3, border_mode='same'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(96, 3, 3))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Conv2D(192, 3, 3, border_mode='same'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(192, 3, 3))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(512))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(256))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(X_train, y_train,batch_size=128, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3508
    },
    "colab_type": "code",
    "id": "QVEq8R4Jnhgo",
    "outputId": "2dee0a7b-0867-4d0c-f59e-c79963b1f059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36375 samples, validate on 12125 samples\n",
      "Epoch 1/100\n",
      "36375/36375 [==============================] - 23s 634us/step - loss: 2.3186 - acc: 0.2744 - val_loss: 1.9259 - val_acc: 0.3236\n",
      "Epoch 2/100\n",
      "36375/36375 [==============================] - 19s 515us/step - loss: 1.8557 - acc: 0.3878 - val_loss: 1.8938 - val_acc: 0.3595\n",
      "Epoch 3/100\n",
      "36375/36375 [==============================] - 18s 508us/step - loss: 1.6984 - acc: 0.4459 - val_loss: 1.9673 - val_acc: 0.3544\n",
      "Epoch 4/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 1.5757 - acc: 0.4878 - val_loss: 1.4188 - val_acc: 0.5282\n",
      "Epoch 5/100\n",
      "36375/36375 [==============================] - 19s 510us/step - loss: 1.4646 - acc: 0.5174 - val_loss: 1.3504 - val_acc: 0.5508\n",
      "Epoch 6/100\n",
      "36375/36375 [==============================] - 19s 510us/step - loss: 1.3565 - acc: 0.5469 - val_loss: 1.4182 - val_acc: 0.5325\n",
      "Epoch 7/100\n",
      "36375/36375 [==============================] - 18s 504us/step - loss: 1.2830 - acc: 0.5725 - val_loss: 1.4138 - val_acc: 0.5297\n",
      "Epoch 8/100\n",
      "36375/36375 [==============================] - 18s 504us/step - loss: 1.2232 - acc: 0.5957 - val_loss: 1.2782 - val_acc: 0.5727\n",
      "Epoch 9/100\n",
      "36375/36375 [==============================] - 18s 507us/step - loss: 1.1887 - acc: 0.6076 - val_loss: 1.0765 - val_acc: 0.6545\n",
      "Epoch 10/100\n",
      "36375/36375 [==============================] - 18s 508us/step - loss: 1.1539 - acc: 0.6224 - val_loss: 1.1772 - val_acc: 0.6223\n",
      "Epoch 11/100\n",
      "36375/36375 [==============================] - 19s 509us/step - loss: 1.1234 - acc: 0.6344 - val_loss: 1.0465 - val_acc: 0.6707\n",
      "Epoch 12/100\n",
      "36375/36375 [==============================] - 18s 507us/step - loss: 1.1034 - acc: 0.6432 - val_loss: 1.1243 - val_acc: 0.6379\n",
      "Epoch 13/100\n",
      "36375/36375 [==============================] - 18s 508us/step - loss: 1.0828 - acc: 0.6496 - val_loss: 1.0785 - val_acc: 0.6593\n",
      "Epoch 14/100\n",
      "36375/36375 [==============================] - 18s 499us/step - loss: 1.0537 - acc: 0.6597 - val_loss: 1.0437 - val_acc: 0.6676\n",
      "Epoch 15/100\n",
      "36375/36375 [==============================] - 18s 505us/step - loss: 1.0315 - acc: 0.6673 - val_loss: 1.0629 - val_acc: 0.6638\n",
      "Epoch 16/100\n",
      "36375/36375 [==============================] - 18s 508us/step - loss: 1.0165 - acc: 0.6733 - val_loss: 1.0295 - val_acc: 0.6796\n",
      "Epoch 17/100\n",
      "36375/36375 [==============================] - 18s 508us/step - loss: 0.9980 - acc: 0.6818 - val_loss: 0.9742 - val_acc: 0.6962\n",
      "Epoch 18/100\n",
      "36375/36375 [==============================] - 18s 509us/step - loss: 0.9791 - acc: 0.6862 - val_loss: 1.1145 - val_acc: 0.6496\n",
      "Epoch 19/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.9709 - acc: 0.6898 - val_loss: 0.9761 - val_acc: 0.6991\n",
      "Epoch 20/100\n",
      "36375/36375 [==============================] - 19s 514us/step - loss: 0.9556 - acc: 0.6935 - val_loss: 0.9613 - val_acc: 0.7042\n",
      "Epoch 21/100\n",
      "36375/36375 [==============================] - 19s 510us/step - loss: 0.9272 - acc: 0.7034 - val_loss: 0.9744 - val_acc: 0.7088\n",
      "Epoch 22/100\n",
      "36375/36375 [==============================] - 18s 506us/step - loss: 0.9260 - acc: 0.7038 - val_loss: 0.9815 - val_acc: 0.6988\n",
      "Epoch 23/100\n",
      "36375/36375 [==============================] - 18s 506us/step - loss: 0.9071 - acc: 0.7130 - val_loss: 0.9580 - val_acc: 0.7067\n",
      "Epoch 24/100\n",
      "36375/36375 [==============================] - 18s 503us/step - loss: 0.9004 - acc: 0.7128 - val_loss: 0.9969 - val_acc: 0.6977\n",
      "Epoch 25/100\n",
      "36375/36375 [==============================] - 18s 506us/step - loss: 0.8842 - acc: 0.7164 - val_loss: 0.9755 - val_acc: 0.7053\n",
      "Epoch 26/100\n",
      "36375/36375 [==============================] - 18s 507us/step - loss: 0.8761 - acc: 0.7231 - val_loss: 1.0264 - val_acc: 0.6825\n",
      "Epoch 27/100\n",
      "36375/36375 [==============================] - 18s 501us/step - loss: 0.8614 - acc: 0.7236 - val_loss: 0.9499 - val_acc: 0.7107\n",
      "Epoch 28/100\n",
      "36375/36375 [==============================] - 18s 487us/step - loss: 0.8541 - acc: 0.7276 - val_loss: 0.9506 - val_acc: 0.7147\n",
      "Epoch 29/100\n",
      "36375/36375 [==============================] - 18s 489us/step - loss: 0.8371 - acc: 0.7344 - val_loss: 0.9437 - val_acc: 0.7155\n",
      "Epoch 30/100\n",
      "36375/36375 [==============================] - 18s 489us/step - loss: 0.8329 - acc: 0.7350 - val_loss: 0.9514 - val_acc: 0.7156\n",
      "Epoch 31/100\n",
      "36375/36375 [==============================] - 18s 489us/step - loss: 0.8143 - acc: 0.7394 - val_loss: 0.9377 - val_acc: 0.7231\n",
      "Epoch 32/100\n",
      "36375/36375 [==============================] - 18s 501us/step - loss: 0.8208 - acc: 0.7382 - val_loss: 0.9293 - val_acc: 0.7231\n",
      "Epoch 33/100\n",
      "36375/36375 [==============================] - 18s 495us/step - loss: 0.8049 - acc: 0.7440 - val_loss: 0.9506 - val_acc: 0.7154\n",
      "Epoch 34/100\n",
      "36375/36375 [==============================] - 18s 497us/step - loss: 0.7927 - acc: 0.7456 - val_loss: 0.9536 - val_acc: 0.7154\n",
      "Epoch 35/100\n",
      "36375/36375 [==============================] - 18s 497us/step - loss: 0.7847 - acc: 0.7504 - val_loss: 0.9687 - val_acc: 0.7136\n",
      "Epoch 36/100\n",
      "36375/36375 [==============================] - 18s 498us/step - loss: 0.7784 - acc: 0.7515 - val_loss: 0.9880 - val_acc: 0.7070\n",
      "Epoch 37/100\n",
      "36375/36375 [==============================] - 18s 496us/step - loss: 0.7726 - acc: 0.7531 - val_loss: 0.9378 - val_acc: 0.7245\n",
      "Epoch 38/100\n",
      "36375/36375 [==============================] - 18s 486us/step - loss: 0.7766 - acc: 0.7506 - val_loss: 0.9583 - val_acc: 0.7155\n",
      "Epoch 39/100\n",
      "36375/36375 [==============================] - 18s 489us/step - loss: 0.7505 - acc: 0.7574 - val_loss: 0.9261 - val_acc: 0.7281\n",
      "Epoch 40/100\n",
      "36375/36375 [==============================] - 18s 491us/step - loss: 0.7507 - acc: 0.7603 - val_loss: 0.9285 - val_acc: 0.7264\n",
      "Epoch 41/100\n",
      "36375/36375 [==============================] - 18s 493us/step - loss: 0.7441 - acc: 0.7612 - val_loss: 0.9609 - val_acc: 0.7166\n",
      "Epoch 42/100\n",
      "36375/36375 [==============================] - 18s 501us/step - loss: 0.7318 - acc: 0.7643 - val_loss: 0.9028 - val_acc: 0.7369\n",
      "Epoch 43/100\n",
      "36375/36375 [==============================] - 18s 498us/step - loss: 0.7298 - acc: 0.7659 - val_loss: 0.9349 - val_acc: 0.7284\n",
      "Epoch 44/100\n",
      "36375/36375 [==============================] - 19s 510us/step - loss: 0.7217 - acc: 0.7671 - val_loss: 0.9334 - val_acc: 0.7275\n",
      "Epoch 45/100\n",
      "36375/36375 [==============================] - 18s 508us/step - loss: 0.7194 - acc: 0.7686 - val_loss: 0.9562 - val_acc: 0.7186\n",
      "Epoch 46/100\n",
      "36375/36375 [==============================] - 19s 515us/step - loss: 0.7094 - acc: 0.7708 - val_loss: 0.9359 - val_acc: 0.7265\n",
      "Epoch 47/100\n",
      "36375/36375 [==============================] - 19s 513us/step - loss: 0.7015 - acc: 0.7748 - val_loss: 0.9522 - val_acc: 0.7219\n",
      "Epoch 48/100\n",
      "36375/36375 [==============================] - 19s 513us/step - loss: 0.6993 - acc: 0.7754 - val_loss: 0.9252 - val_acc: 0.7361\n",
      "Epoch 49/100\n",
      "36375/36375 [==============================] - 19s 514us/step - loss: 0.6931 - acc: 0.7755 - val_loss: 0.9487 - val_acc: 0.7320\n",
      "Epoch 50/100\n",
      "36375/36375 [==============================] - 19s 510us/step - loss: 0.6911 - acc: 0.7761 - val_loss: 0.9678 - val_acc: 0.7214\n",
      "Epoch 51/100\n",
      "36375/36375 [==============================] - 19s 515us/step - loss: 0.6815 - acc: 0.7794 - val_loss: 0.9629 - val_acc: 0.7224\n",
      "Epoch 52/100\n",
      "36375/36375 [==============================] - 19s 513us/step - loss: 0.6797 - acc: 0.7797 - val_loss: 0.9252 - val_acc: 0.7317\n",
      "Epoch 53/100\n",
      "36375/36375 [==============================] - 19s 513us/step - loss: 0.6719 - acc: 0.7811 - val_loss: 0.9552 - val_acc: 0.7270\n",
      "Epoch 54/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.6586 - acc: 0.7850 - val_loss: 0.9459 - val_acc: 0.7264\n",
      "Epoch 55/100\n",
      "36375/36375 [==============================] - 19s 510us/step - loss: 0.6695 - acc: 0.7830 - val_loss: 0.9246 - val_acc: 0.7353\n",
      "Epoch 56/100\n",
      "36375/36375 [==============================] - 19s 515us/step - loss: 0.6550 - acc: 0.7869 - val_loss: 0.9346 - val_acc: 0.7331\n",
      "Epoch 57/100\n",
      "36375/36375 [==============================] - 19s 515us/step - loss: 0.6501 - acc: 0.7875 - val_loss: 0.9185 - val_acc: 0.7424\n",
      "Epoch 58/100\n",
      "36375/36375 [==============================] - 18s 508us/step - loss: 0.6462 - acc: 0.7909 - val_loss: 0.9500 - val_acc: 0.7290\n",
      "Epoch 59/100\n",
      "36375/36375 [==============================] - 19s 512us/step - loss: 0.6456 - acc: 0.7888 - val_loss: 0.9416 - val_acc: 0.7296\n",
      "Epoch 60/100\n",
      "36375/36375 [==============================] - 19s 512us/step - loss: 0.6384 - acc: 0.7914 - val_loss: 0.9245 - val_acc: 0.7348\n",
      "Epoch 61/100\n",
      "36375/36375 [==============================] - 19s 510us/step - loss: 0.6242 - acc: 0.7957 - val_loss: 0.9665 - val_acc: 0.7259\n",
      "Epoch 62/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.6290 - acc: 0.7943 - val_loss: 0.9356 - val_acc: 0.7403\n",
      "Epoch 63/100\n",
      "36375/36375 [==============================] - 19s 513us/step - loss: 0.6130 - acc: 0.8016 - val_loss: 0.9366 - val_acc: 0.7341\n",
      "Epoch 64/100\n",
      "36375/36375 [==============================] - 19s 510us/step - loss: 0.6224 - acc: 0.7947 - val_loss: 0.9475 - val_acc: 0.7329\n",
      "Epoch 65/100\n",
      "36375/36375 [==============================] - 19s 512us/step - loss: 0.6092 - acc: 0.7999 - val_loss: 0.9535 - val_acc: 0.7314\n",
      "Epoch 66/100\n",
      "36375/36375 [==============================] - 19s 514us/step - loss: 0.6208 - acc: 0.7955 - val_loss: 0.9584 - val_acc: 0.7268\n",
      "Epoch 67/100\n",
      "36375/36375 [==============================] - 19s 514us/step - loss: 0.6136 - acc: 0.7956 - val_loss: 1.0157 - val_acc: 0.7087\n",
      "Epoch 68/100\n",
      "36375/36375 [==============================] - 19s 515us/step - loss: 0.6046 - acc: 0.8003 - val_loss: 0.9344 - val_acc: 0.7353\n",
      "Epoch 69/100\n",
      "36375/36375 [==============================] - 19s 516us/step - loss: 0.5998 - acc: 0.8019 - val_loss: 0.9450 - val_acc: 0.7301\n",
      "Epoch 70/100\n",
      "36375/36375 [==============================] - 19s 516us/step - loss: 0.5885 - acc: 0.8047 - val_loss: 0.9790 - val_acc: 0.7150\n",
      "Epoch 71/100\n",
      "36375/36375 [==============================] - 19s 512us/step - loss: 0.5928 - acc: 0.8043 - val_loss: 0.9342 - val_acc: 0.7385\n",
      "Epoch 72/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.5817 - acc: 0.8086 - val_loss: 0.9689 - val_acc: 0.7261\n",
      "Epoch 73/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.5822 - acc: 0.8101 - val_loss: 0.9767 - val_acc: 0.7266\n",
      "Epoch 74/100\n",
      "36375/36375 [==============================] - 18s 502us/step - loss: 0.5893 - acc: 0.8030 - val_loss: 0.9460 - val_acc: 0.7370\n",
      "Epoch 75/100\n",
      "36375/36375 [==============================] - 18s 506us/step - loss: 0.5786 - acc: 0.8093 - val_loss: 0.9639 - val_acc: 0.7337\n",
      "Epoch 76/100\n",
      "36375/36375 [==============================] - 19s 514us/step - loss: 0.5776 - acc: 0.8051 - val_loss: 0.9911 - val_acc: 0.7226\n",
      "Epoch 77/100\n",
      "36375/36375 [==============================] - 19s 515us/step - loss: 0.5665 - acc: 0.8152 - val_loss: 0.9531 - val_acc: 0.7378\n",
      "Epoch 78/100\n",
      "36375/36375 [==============================] - 19s 509us/step - loss: 0.5679 - acc: 0.8139 - val_loss: 0.9532 - val_acc: 0.7362\n",
      "Epoch 79/100\n",
      "36375/36375 [==============================] - 19s 509us/step - loss: 0.5622 - acc: 0.8111 - val_loss: 0.9512 - val_acc: 0.7325\n",
      "Epoch 80/100\n",
      "36375/36375 [==============================] - 19s 512us/step - loss: 0.5550 - acc: 0.8139 - val_loss: 0.9641 - val_acc: 0.7301\n",
      "Epoch 81/100\n",
      "36375/36375 [==============================] - 19s 514us/step - loss: 0.5650 - acc: 0.8111 - val_loss: 0.9487 - val_acc: 0.7360\n",
      "Epoch 82/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.5622 - acc: 0.8123 - val_loss: 0.9843 - val_acc: 0.7245\n",
      "Epoch 83/100\n",
      "36375/36375 [==============================] - 19s 513us/step - loss: 0.5553 - acc: 0.8129 - val_loss: 0.9597 - val_acc: 0.7348\n",
      "Epoch 84/100\n",
      "36375/36375 [==============================] - 19s 514us/step - loss: 0.5492 - acc: 0.8151 - val_loss: 0.9595 - val_acc: 0.7333\n",
      "Epoch 85/100\n",
      "36375/36375 [==============================] - 19s 516us/step - loss: 0.5524 - acc: 0.8165 - val_loss: 0.9609 - val_acc: 0.7371\n",
      "Epoch 86/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.5421 - acc: 0.8214 - val_loss: 0.9620 - val_acc: 0.7338\n",
      "Epoch 87/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.5417 - acc: 0.8177 - val_loss: 0.9867 - val_acc: 0.7262\n",
      "Epoch 88/100\n",
      "36375/36375 [==============================] - 19s 512us/step - loss: 0.5389 - acc: 0.8194 - val_loss: 0.9740 - val_acc: 0.7308\n",
      "Epoch 89/100\n",
      "36375/36375 [==============================] - 19s 512us/step - loss: 0.5425 - acc: 0.8200 - val_loss: 0.9627 - val_acc: 0.7348\n",
      "Epoch 90/100\n",
      "36375/36375 [==============================] - 19s 513us/step - loss: 0.5429 - acc: 0.8183 - val_loss: 0.9689 - val_acc: 0.7384\n",
      "Epoch 91/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.5302 - acc: 0.8219 - val_loss: 0.9547 - val_acc: 0.7388\n",
      "Epoch 92/100\n",
      "36375/36375 [==============================] - 18s 504us/step - loss: 0.5258 - acc: 0.8250 - val_loss: 0.9554 - val_acc: 0.7361\n",
      "Epoch 93/100\n",
      "36375/36375 [==============================] - 19s 512us/step - loss: 0.5294 - acc: 0.8238 - val_loss: 0.9680 - val_acc: 0.7353\n",
      "Epoch 94/100\n",
      "36375/36375 [==============================] - 18s 508us/step - loss: 0.5239 - acc: 0.8230 - val_loss: 0.9801 - val_acc: 0.7339\n",
      "Epoch 95/100\n",
      "36375/36375 [==============================] - 19s 513us/step - loss: 0.5304 - acc: 0.8231 - val_loss: 0.9573 - val_acc: 0.7344\n",
      "Epoch 96/100\n",
      "36375/36375 [==============================] - 19s 514us/step - loss: 0.5244 - acc: 0.8245 - val_loss: 0.9895 - val_acc: 0.7267\n",
      "Epoch 97/100\n",
      "36375/36375 [==============================] - 19s 513us/step - loss: 0.5210 - acc: 0.8255 - val_loss: 0.9805 - val_acc: 0.7278\n",
      "Epoch 98/100\n",
      "36375/36375 [==============================] - 19s 510us/step - loss: 0.5313 - acc: 0.8230 - val_loss: 0.9773 - val_acc: 0.7301\n",
      "Epoch 99/100\n",
      "36375/36375 [==============================] - 19s 512us/step - loss: 0.5195 - acc: 0.8249 - val_loss: 0.9541 - val_acc: 0.7402\n",
      "Epoch 100/100\n",
      "36375/36375 [==============================] - 19s 511us/step - loss: 0.5075 - acc: 0.8314 - val_loss: 1.0004 - val_acc: 0.7296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcbffb2f278>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1 with 64% accuracy\n",
    "\n",
    "reg=None\n",
    "num_filters=32\n",
    "ac='relu'\n",
    "adm=Adam(lr=0.001,decay=0, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "opt=adm\n",
    "drop_dense=0.5\n",
    "drop_conv=0.5\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(num_filters, (3, 3), activation=ac, kernel_regularizer=reg, input_shape=(32, 32, 1),padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 16x16x3xnum_filters\n",
    "model.add(Dropout(drop_conv))\n",
    "\n",
    "model.add(Conv2D(2*num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(2*num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 8x8x3x(2*num_filters)\n",
    "model.add(Dropout(drop_conv))\n",
    "\n",
    "model.add(Conv2D(4*num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(4*num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 4x4x3x(4*num_filters)\n",
    "model.add(Dropout(drop_conv))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=ac,kernel_regularizer=reg))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(drop_dense))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=opt)\n",
    "model.fit(X_train, y_train,batch_size=128, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a30pWwgAL_cL"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "res = model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XL8lqOz3nhhA"
   },
   "outputs": [],
   "source": [
    "# File creation\n",
    "\n",
    "submission = pd.read_csv('/content/mydrive/My Drive/DM_DATA/sample.csv')\n",
    "submission['label'] = res\n",
    "submission.to_csv('/content/mydrive/My Drive/DM_DATA/submission_model3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8IGAK7GnhhE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DM Kernel 1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
